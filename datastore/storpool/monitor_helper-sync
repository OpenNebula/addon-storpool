#!/bin/bash
#
# -------------------------------------------------------------------------- #
# Copyright 2016-2024, StorPool (storpool.com)                               #
#                                                                            #
# Licensed under the Apache License, Version 2.0 (the "License"); you may    #
# not use this file except in compliance with the License. You may obtain    #
# a copy of the License at                                                   #
#                                                                            #
# http://www.apache.org/licenses/LICENSE-2.0                                 #
#                                                                            #
# Unless required by applicable law or agreed to in writing, software        #
# distributed under the License is distributed on an "AS IS" BASIS,          #
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   #
# See the License for the specific language governing permissions and        #
# limitations under the License.                                             #
#--------------------------------------------------------------------------- #

export PATH="/bin:/sbin:/usr/bin:/usr/sbin:${PATH}"

function splog() { logger -t "ds_sp_${0##*/}" "[$$] $*"; }

set -o pipefail

SP_JSON_PATH="/tmp"
SP_FE_JSON_PATH="/var/cache/addon-storpool-monitor"
ONE_HOME="${ONE_HOME:-/var/lib/one}"


# datastores stats
SP_TEMPLATE_STATUS_JSON="storpool_template_status.json"
SP_TEMPLATE_STATUS_RUN="storpool -B -j template status"
SP_TEMPLATE_STATUS_MINUTES=60

# VM disks stats
SP_VOLUME_SPACE_JSON="storpool_volume_usedSpace.json"
SP_VOLUME_SPACE_RUN="storpool -B -j volume usedSpace"
SP_VOLUME_SPACE_MINUTES=60

# VM disks snapshots stats
SP_SNAPSHOT_SPACE_JSON="storpool_snapshot_space.json"
SP_SNAPSHOT_SPACE_RUN="storpool -B -j snapshot space"
SP_SNAPSHOT_SPACE_MINUTES=65

# Disabled by default
# volume status
SP_VOLUME_STATUS_JSON="storpool_volume_status.json"
#SP_VOLUME_STATUS_RUN="storpool -B -j volume status"
SP_VOLUME_STATUS_MINUTES=5

# Disabled by default
# volume list
SP_VOLUME_LIST_JSON="storpool_volume_list.json"
#SP_VOLUME_LIST_RUN="storpool -B -j volume list"
SP_VOLUME_LIST_MINUTES=1

# Disabled by default
# snapshot list
SP_SNAPSHOT_LIST_JSON="storpool_snapshot_list.json"
#SP_SNAPSHOT_LIST_RUN="storpool -B -j snapshot list"
SP_SNAPSHOT_LIST_MINUTES=1

ONE_VM_POOL_RUN="onevm list -x"
ONE_VM_POOL_XML="onevm.pool.xml"
ONE_VM_POOL_MINUTES=5

# Do sync to remote hosts
MONITOR_SYNC_REMOTE="YES"

# Do template propagate
SP_TEMPLATE_PROPAGATE="YES"

ONEDATASTORE_XML="ds.xml"

AUTO_TEMPLATE=0

PROPAGATE_YES=1

# load config
driverPath="${0%/*}"
if [[ -f "${driverPath}/../../addon-storpoolrc" ]]; then
	# shellcheck source=addon-storpoolrc
	source "${driverPath}/../../addon-storpoolrc"
fi
if [[ -f "${driverPath}/../../${0##*/}rc" ]]; then
	# /var/lib/one/remotes/monitor_helper-syncrc
	# shellcheck source=/dev/null
	source "${driverPath}/../../${0##*/}rc"
fi

umask -S u=rwx,g=rwx,o= >/dev/null

ONE_PX="${ONE_PX:-one}"

if [[ -d "/opt/storpool/python3/bin" ]]; then
    export PATH="/opt/storpool/python3/bin:${PATH}"
fi

function boolTrue()
{
   case "${!1^^}" in
       1|Y|YES|T|TRUE|ON)
           return 0
           ;;
       *)
           return 1
   esac
}

# locking...
lockFile="/var/lock/one/${0##*/}.lock"
if [[ -f "${lockFile}" ]]; then
	pid=$(<"${lockFile}")
	mTime=$(stat -c %Y "${lockFile}")
	if [[ -d "/proc/${pid}/" ]]; then
		cmdline="$(<"/proc/${pid}/cmdline")"
		if [[ "${cmdline//${0##*/}/}" == "${cmdline}" ]]; then
			splog "Found ${lockFile} with PID ${pid}. Last modified ${mTime} (stale file)"
		else
			splog "Found ${lockFile} with PID ${pid}. Last modified ${mTime} (still running)"
			exit 0
		fi
	else
		splog "Can't find process info for PID ${pid}. Assuming stale lock ${lockFile}"
	fi
fi

# check that the oned process is sunning
if pgrep 'oned' >/dev/null; then
	if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
		splog "[D] The oned process is running."
	fi
else
	if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
		splog "[D] There is no oned process running. Exit."
	fi
	exit 0
fi

# try detecting RAFT_LEADER_IP from opennebula's config
ONE_CONFIG="${ONE_HOME:-/var/lib/one}/config"
if [[ -z "${RAFT_LEADER_IP}" ]] && [[ -f "${ONE_CONFIG}" ]]; then
	#RAFT_LEADER_HOOK=ARGUMENTS=leader vlan11 10.163.1.250,COMMAND=raft/vip.sh
	RAFT_IP="$(awk '$0 ~ /^RAFT_LEADER_HOOK/{print $3}' "${ONE_CONFIG}" | tail -n 1 || true)"
	if [[ -n "${RAFT_IP}" ]]; then
		RAFT_LEADER_IP="${RAFT_IP%%/*}"
		RAFT_LEADER_IP="${RAFT_LEADER_IP%%,*}"
	fi
fi

if [[ -n "${RAFT_LEADER_IP#disabled}" ]]; then
	tmp="$(ip route get "${RAFT_LEADER_IP}" 2>/dev/null | head -n 1)"
	if [[ "${tmp:0:5}" == "local" ]]; then
		if boolTrue "DDEBUG_MOINTOR_HELPER_SYNC"; then
			splog "[DD]Found leader IP (${RAFT_LEADER_IP})."
		fi
	else
		if boolTrue "DDEBUG_MOINTOR_HELPER_SYNC"; then
			splog "[DD] There is no leader IP found (${RAFT_LEADER_IP}). Exit."
		fi
		exit 0
	fi
fi

echo "$$" >"${lockFile}"
# shellcheck disable=SC2064
trap "rm -f \"${lockFile}\"" TERM INT QUIT EXIT

# Global arrays ...
declare -a template_data
declare -A jFiles

function doExpand()
{
	local _name="$1" _val
	eval "_val=\$${_name}"
	_val="${_val//_DATASTORE_ID_/${DS_ID}}"
	_val="${_val//_CLUSTER_ID_/${CLUSTER_ID}}"
	_val="${_val//_SP_API_HTTP_HOST_/${SP_API_HTTP_HOST}}"
	_val="${_val//_SP_JSON_PATH_/${SP_JSON_PATH}}"
	_val="${_val//_SP_FE_JSON_PATH_/${SP_FE_JSON_PATH}}"
	eval "${_name}=${_val}"
}

function run_task()
{
	local _run="$1" _jsonFile="$2" _cacheTime="$3" _reloadCache="$4" _runonly="$5"
	local _sp_api_http_host="${SP_API_HTTP_HOST:-0.0.0.0}"
	local _cached=0 _ret=1

	mkdir -p "${_jsonFile%/*}"

	if [[ "${sp_api_list/|${_run}${_sp_api_http_host}|/}" == "${sp_api_list}" ]] || boolTrue "_reloadCache"; then
		sp_api_list+="|${_run}${_sp_api_http_host}|"
		if [[ -f "${_jsonFile}${_sp_api_http_host}" ]]; then
			if [[ -n "${_cacheTime}" ]] && [[ "${_cacheTime//[[:digit:]]/}" == "" ]]; then
				seconds=$((_cacheTime * 60))
				mTime=$(stat -c %Y "${_jsonFile}${_sp_api_http_host}")
				dTime=$((mTime + seconds))
				cTime=$(date +%s)
				if [[ "${cTime}" -lt "${dTime}" ]]; then
					_cached=$((cTime-dTime))
 				fi
			fi
			if boolTrue "_reloadCache"; then
				splog "run_task: Force cache reset. Cache time was ${_cached}"
				_cached=0
			fi
		else
            if [[ -z "${_runonly}" ]]; then
                splog "File not found! ${_jsonFile}${_sp_api_http_host}"
            fi
		fi
		if [[ "${_cached}" -ge 0 ]]; then
			eval "${_run}" 2>/dev/null >"${_jsonFile}New"
			_ret=$?
			if boolTrue "DEBUG_MOINTOR_HELPER_SYNC" || [[ "${_ret}" -ne 0 ]]; then
				splog "[D] run_task:(${_ret}) ${_run} > ${_jsonFile}New [${_cached}]"
				if [[ "${_ret}" -ne 0 ]]; then
					return "${_ret}"
				fi
			fi
			mv -f "${_jsonFile}New" "${_jsonFile}"
			_ret=$?
			if [[ "${_ret}" -ne 0 ]]; then
				splog "Can't move ${_jsonFile}New to ${_jsonFile}"
				return "${_ret}"
			fi
            if [[ -n "${_runonly}" ]]; then
                return 0
            fi
			cp -f "${_jsonFile}" "${_jsonFile}${_sp_api_http_host}"
			_ret=$?
			if boolTrue "DEBUG_MOINTOR_HELPER_SYNC" || [[ "${_ret}" -ne 0 ]]; then
				splog "[D] run_task:(${_ret}) cp ${_jsonFile} ${_jsonFile}${_sp_api_http_host}"
			fi
		fi
	fi
	if [[ -d "${SP_MONITOR_CACHE_CLUSTER}" ]]; then
		ln -sf "${_jsonFile}${_sp_api_http_host}" "${SP_MONITOR_CACHE_CLUSTER}/${_jsonFile##*/}"
		_ret=$?
		if boolTrue "DEBUG_MOINTOR_HELPER_SYNC" || [[ "${_ret}" -ne 0 ]]; then
			splog "[D] (${_ret}) ln -sf ${_jsonFile}${_sp_api_http_host} ${SP_MONITOR_CACHE_CLUSTER}/${_jsonFile##*/} cached:${_cached} seconds"
		fi
	else
		splog "directory not found ${SP_MONITOR_CACHE_CLUSTER}"
	fi
	jFiles[${_jsonFile}]="${_jsonFile##*/}"
	return "${_ret}"
}

if [[ ! -d "${SP_FE_JSON_PATH}" ]]; then
	mkdir -p "${SP_FE_JSON_PATH}"
fi
# shellcheck disable=SC2086
onedatastore list ${ONE_ARGS:-} -x >"${SP_FE_JSON_PATH}/${ONEDATASTORE_XML}"
ret=$?
if [[ "${ret}" -ne 0 ]]; then
	splog "Error: Can't get datastore XML! $(head -n 1 "${SP_FE_JSON_PATH}/${ONEDATASTORE_XML}" || true) (ret:${ret})"
	exit "${ret}"
fi

_XPATH="${driverPath}/../xpath_multi.py"
declare -a _XPATH_A _XPATH_QUERY
_XPATH_A=(
    "${_XPATH}"
    "-s"
)
_XPATH_QUERY=(
    "/DATASTORE_POOL/DATASTORE/ID"
    "/DATASTORE_POOL/DATASTORE/STATE"
    "/DATASTORE_POOL/DATASTORE/CLUSTER_ID"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/TM_MAD"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_REPLICATION"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_PLACEALL"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_PLACETAIL"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_PLACEHEAD"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_IOPS"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_BW"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_AUTO_TEMPLATE"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_TEMPLATE_PROPAGATE"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_API_HTTP_HOST"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_API_HTTP_PORT"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_AUTH_TOKEN"
    "/DATASTORE_POOL/DATASTORE/TEMPLATE/SP_SKIP_MONITOR"
)

unset i XPATH_ELEMENTS
while IFS='' read -r -u "${xpathfd}" element; do
	XPATH_ELEMENTS[i++]="${element}"
done {xpathfd}< <("${_XPATH_A[@]}" <"${SP_FE_JSON_PATH}/${ONEDATASTORE_XML}" "${_XPATH_QUERY[@]}" || true)
unset i
_DS_ID="${XPATH_ELEMENTS[i++]}"
_DS_STATE="${XPATH_ELEMENTS[i++]}"
_DS_CLUSTER_ID="${XPATH_ELEMENTS[i++]}"
_DS_TM_MAD="${XPATH_ELEMENTS[i++]}"
_SP_REPLICATION="${XPATH_ELEMENTS[i++]}"
_SP_PLACEALL="${XPATH_ELEMENTS[i++]}"
_SP_PLACETAIL="${XPATH_ELEMENTS[i++]}"
_SP_PLACEHEAD="${XPATH_ELEMENTS[i++]}"
_SP_IOPS="${XPATH_ELEMENTS[i++]}"
_SP_BW="${XPATH_ELEMENTS[i++]}"
_SP_AUTO_TEMPLATE="${XPATH_ELEMENTS[i++]}"
_SP_TEMPLATE_PROPAGATE="${XPATH_ELEMENTS[i++]}"
_SP_API_HTTP_HOST="${XPATH_ELEMENTS[i++]}"
_SP_API_HTTP_PORT="${XPATH_ELEMENTS[i++]}"
_SP_AUTH_TOKEN="${XPATH_ELEMENTS[i++]}"
_SP_SKIP_MONITOR="${XPATH_ELEMENTS[i++]}"

IFS=';' read -ra DS_ID_ARRAY <<<"${_DS_ID}"
IFS=';' read -ra DS_STATE_ARRAY <<<"${_DS_STATE}"
IFS=';' read -ra DS_CLUSTER_ID_ARRAY <<<"${_DS_CLUSTER_ID}"
IFS=';' read -ra DS_TM_MAD_ARRAY <<<"${_DS_TM_MAD}"
IFS=';' read -ra SP_REPLICATION_ARRAY <<<"${_SP_REPLICATION}"
IFS=';' read -ra SP_PLACEALL_ARRAY <<<"${_SP_PLACEALL}"
IFS=';' read -ra SP_PLACETAIL_ARRAY <<<"${_SP_PLACETAIL}"
IFS=';' read -ra SP_PLACEHEAD_ARRAY <<<"${_SP_PLACEHEAD}"
IFS=';' read -ra SP_IOPS_ARRAY <<<"${_SP_IOPS}"
IFS=';' read -ra SP_BW_ARRAY <<<"${_SP_BW}"
IFS=';' read -ra SP_AUTO_TEMPLATE_ARRAY <<<"${_SP_AUTO_TEMPLATE}"
IFS=';' read -ra SP_TEMPLATE_PROPAGATE_ARRAY <<<"${_SP_TEMPLATE_PROPAGATE}"
IFS=';' read -ra SP_API_HTTP_HOST_ARRAY <<<"${_SP_API_HTTP_HOST}"
IFS=';' read -ra SP_API_HTTP_PORT_ARRAY <<<"${_SP_API_HTTP_PORT}"
IFS=';' read -ra SP_AUTH_TOKEN_ARRAY <<<"${_SP_AUTH_TOKEN}"
IFS=';' read -ra SP_SKIP_MONITOR_ARRAY <<<"${_SP_SKIP_MONITOR}"

tmpDir="$(mktemp --tmpdir -d one-sp-XXXXXXXX)"
# shellcheck disable=SC2064
trap "rm -rf \"${lockFile}\" \"${tmpDir}\"" TERM INT QUIT HUP EXIT


for i in "${!DS_ID_ARRAY[@]}"; do
	[[ "${DS_TM_MAD_ARRAY[i]}" == "storpool" ]] || continue

	cmd=
	comment=
	DS_ID=${DS_ID_ARRAY[i]}
	template_name="${ONE_PX}-ds-${DS_ID}"
	sp_token="${SP_AUTH_TOKEN_ARRAY[i]}"
	if [[ -n "${sp_token}" ]]; then
		export SP_AUTH_TOKEN="${sp_token}"
	else
		unset SP_AUTH_TOKEN
	fi
	sp_host="${SP_API_HTTP_HOST_ARRAY[i]}"
	if [[ -n "${sp_host}" ]]; then
		export SP_API_HTTP_HOST="${sp_host}"
	else
		unset SP_API_HTTP_HOST
	fi
	sp_port="${SP_API_HTTP_PORT_ARRAY[i]}"
	if [[ -n "${sp_port}" ]]; then
		export SP_API_HTTP_PORT="${sp_port}"
	else
		unset SP_API_HTTP_PORT
	fi
	export SP_PROPAGATE="${SP_TEMPLATE_PROPAGATE_ARRAY[i]:-${SP_TEMPLATE_PROPAGATE:-}}"
	if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
		if [[ -n "${SP_AUTH_TOKEN}${SP_API_HTTP_HOST}${SP_API_HTTP_PORT}" ]]; then
			splog "[D] API_TOKEN:${SP_AUTH_TOKEN:+DEFINED} API_HOST:${SP_API_HTTP_HOST} API_PORT:${SP_API_HTTP_PORT}"
		fi
	fi

	if boolTrue "SP_SKIP_MONITOR_ARRAY[i]"; then
		splog "DS_ID ${DS_ID} Skipped (SP_SKIP_MONITOR=${SP_SKIP_MONITOR_ARRAY[i]})"
		continue
	fi
    if [[ "${DS_STATE_ARRAY[i]}" != "0" ]]; then
	    if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
            splog "[D] Skipped Datastore ${DS_ID} STATE=${DS_STATE_ARRAY[i]}"
        fi
        continue
    fi

	#old style
	read -ra CLUSTER_IDS <<<"${DS_CLUSTER_ID_ARRAY[i]}"
	if [[ ${#CLUSTER_IDS[@]} -eq 0 ]]; then
		#new style
		_XPATH="${driverPath}/../xpath.rb"
		_XPATH_A=(
			"${_XPATH}"
			"--stdin"
		)
		_XPATH_QUERY=(
			"%m%/DATASTORE_POOL/DATASTORE[ID=${DS_ID}]/CLUSTERS/ID"
		)
		unset j
		while IFS='' read -r -u "${xpathfd}" -d '' _element; do
			CLUSTER_IDS[j++]="${_element}"
		done {xpathfd}< <("${_XPATH_A[@]}" <"${SP_FE_JSON_PATH}/${ONEDATASTORE_XML}" "${_XPATH_QUERY[@]}" || true)
	fi
	if [[ -n "${DDEBUG_MOINTOR_HELPER_SYNC:-}" ]]; then
		splog "[DD] DS_ID=${DS_ID} ${SP_FE_JSON_PATH}/${ONEDATASTORE_XML} CLUSTER_IDS:${CLUSTER_IDS[*]}"
	fi

	# create/update the template in StorPool
	# or update ONE datastore

	tmp="$(storpool -B -j template list 2>"${tmpDir}/error.log"| jq -r ".data|map(select(.name==\"${template_name}\"))|.[]|[.replication,.placeAll,.placeTail,.iops,.bw,.placeHead]|@csv" || true)"
	ret=$?
	if [[ -z "${tmp}" ]]; then
		if [[ ${ret} -ne 0 ]] && [[ -s "${tmpDir}/error.log" ]]; then
			while read -r -u "${errorfd}" line; do
				splog "(${ret}) Error:${line}"
			done {errorfd}< <(cat "${tmpDir}/error.log" || true)
		fi
		splog "Missing StorPool template '${template_name}' for datastore ${DS_ID}"
		reload_template=1
		clusters=
	else
		reload_template=""
	fi

	tmpFile="${tmpDir}/${DS_ID}.update"

	read -ra template_data <<<"${tmp//,/ }"
	old="${template_data[0]//\"/}"
	new="${SP_REPLICATION_ARRAY[i]}"
	if [[ "${old}" != "${new}" ]]; then
		if boolTrue "AUTO_TEMPLATE"; then
			if [[ -n "${new:-3}" ]]; then
				cmd+="replication ${new} "
				comment+=" replication:${old}"
			fi
		else
			if [[ -n "${old}" ]]; then
				echo "SP_REPLICATION=${old}" >>"${tmpFile}"
				splog "DS_ID ${DS_ID} update SP_REPLICATION=${old}"
			fi
		fi
	fi
	old="${template_data[1]//\"/}"
	new="${SP_PLACEALL_ARRAY[i]}"
	if [[ "${old}" != "${new}" ]]; then
		if boolTrue "AUTO_TEMPLATE"; then
			if [[ -n "${new}" ]]; then
				cmd+="placeAll ${new} "
				comment+=" placeAll:${old}"
			fi
		else
			if [[ -n "${old}" ]]; then
				echo "SP_PLACEALL=${old}" >>"${tmpFile}"
				splog "DS_ID ${DS_ID} update SP_PLACEALL=${old}"
			fi
		fi
	fi
	old="${template_data[2]//\"/}"
	new="${SP_PLACETAIL_ARRAY[i]}"
	if [[ "${old}" != "${new}" ]]; then
		if boolTrue "AUTO_TEMPLATE"; then
			if [[ -n "${new}" ]]; then
				cmd+="placeTail ${new} "
				comment+=" placeTail:${old}"
			fi
		else
			if [[ -n "${old}" ]]; then
				echo "SP_PLACETAIL=${old}" >>"${tmpFile}"
				splog "DS_ID ${DS_ID} update SP_PLACETAIL=${old}"
			fi
		fi
	fi
	old="${template_data[3]//\"/}"
	new="${SP_IOPS_ARRAY[i]:--}"
	if [[ "${old}" != "${new}" ]]; then
		if boolTrue "AUTO_TEMPLATE"; then
			if [[ -n "${new}" ]]; then
				cmd+="iops ${new} "
				comment+=" iops:${old}"
			fi
		else
			if [[ -n "${old}" ]]; then
				echo "SP_IOPS=${old}" >>"${tmpFile}"
				splog "DS_ID ${DS_ID} update SP_IOPS=${old}"
			fi
		fi
	fi
	old="${template_data[4]//\"/}"
	new="${SP_BW_ARRAY[i]:--}"
	if [[ "${old}" != "${new}" ]]; then
		if boolTrue "AUTO_TEMPLATE"; then
			if [[ -n "${new}" ]]; then
				cmd+="bw ${new} "
				comment+=" bw:${old}"
			fi
		else
			if [[ -n "${old}" ]]; then
				echo "SP_BW=${old}" >>"${tmpFile}"
				splog "DS_ID ${DS_ID} update SP_BW=${old}"
			fi
		fi
	fi
	old="${template_data[5]//\"/}"
	new="${SP_PLACEHEAD_ARRAY[i]}"
	if [[ "${old}" != "${new}" ]]; then
		if boolTrue "AUTO_TEMPLATE"; then
			if [[ -n "${new}" ]]; then
				cmd+="placeHead ${new} "
				comment+=" placeHead:${old}"
			fi
		else
			if [[ -n "${old}" ]]; then
				echo "SP_PLACEHEAD=${old}" >>"${tmpFile}"
				splog "DS_ID ${DS_ID} update SP_PLACEHEAD=${old}"
			fi
		fi
	fi
	old="${AUTO_TEMPLATE:-0}"
	new="${SP_AUTO_TEMPLATE_ARRAY[i]}"
	if [[ "${old}" != "${new}" ]]; then
		echo "SP_AUTO_TEMPLATE=${old}" >>"${tmpFile}"
		splog "DS_ID ${DS_ID} update SP_AUTO_TEMPLATE=${old}"
	fi

	if boolTrue "AUTO_TEMPLATE"; then
		if [[ -n "${cmd}" ]]; then
			# shellcheck disable=SC2086
			storpool -B template "${template_name}" ${cmd}
			splog "($?) template ${template_name} ${cmd} OLD:${comment} API:${SP_API_HTTP_HOST}"
			if boolTrue "SP_PROPAGATE"; then
				storpool -B template "${template_name}" propagate ${PROPAGATE_YES:+yes} >/dev/null 2>&1
				splog "($?) template ${template_name} propagate ${PROPAGATE_YES:+yes}"
			fi
		fi
	fi
	if [[ -s "${tmpFile}" ]]; then
		# shellcheck disable=SC2086
		onedatastore update ${ONE_ARGS:-} "${DS_ID}" --append "${tmpFile}"
		splog "($?) onedatastore update ${ONE_ARGS} ${DS_ID} --append ${tmpFile}"
	fi

	for CLUSTER_ID in "${CLUSTER_IDS[@]}"; do
		if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
			splog "[D] CLUSTER_ID:${CLUSTER_ID} DS_ID:${DS_ID} API:${SP_API_HTTP_HOST} clusters:${clusters}"
		fi
		if [[ "${clusters/|${CLUSTER_ID}|/}" == "${clusters}" ]]; then
			clusters+="|${CLUSTER_ID}|"

			SP_MONITOR_CACHE_CLUSTER="${SP_FE_JSON_PATH}/${CLUSTER_ID}"
			if [[ ! -d "${SP_MONITOR_CACHE_CLUSTER}" ]]; then
				mkdir -p "${SP_MONITOR_CACHE_CLUSTER}"
				splog "($?) mkdir ${SP_MONITOR_CACHE_CLUSTER}"
			fi

			if [[ -n "${SP_TEMPLATE_STATUS_RUN}" ]]; then
				rFile="${SP_FE_JSON_PATH}/${SP_TEMPLATE_STATUS_JSON##*/}"
				doExpand "rFile"
				run_task "${SP_TEMPLATE_STATUS_RUN}" "${rFile}" "${SP_TEMPLATE_STATUS_MINUTES}" "${reload_template}"
			fi
			if [[ -n "${SP_VOLUME_SPACE_RUN}" ]]; then
				rFile="${SP_FE_JSON_PATH}/${SP_VOLUME_SPACE_JSON##*/}"
				doExpand "rFile"
				run_task "${SP_VOLUME_SPACE_RUN}" "${rFile}" "${SP_VOLUME_SPACE_MINUTES}"
			fi
			if [[ -n "${SP_SNAPSHOT_SPACE_RUN}" ]]; then
				rFile="${SP_FE_JSON_PATH}/${SP_SNAPSHOT_SPACE_JSON##*/}"
				doExpand "rFile"
				run_task "${SP_SNAPSHOT_SPACE_RUN}" "${rFile}" "${SP_SNAPSHOT_SPACE_MINUTES}"
			fi
			if [[ -n "${SP_VOLUME_STATUS_RUN}" ]]; then
				rFile="${SP_FE_JSON_PATH}/${SP_VOLUME_STATUS_JSON##*/}"
				doExpand "rFile"
				run_task "${SP_VOLUME_STATUS_RUN}" "${rFile}" "${SP_VOLUME_STATUS_MINUTES}"
			fi
			if [[ -n "${SP_VOLUME_LIST_RUN}" ]]; then
				rFile="${SP_FE_JSON_PATH}/${SP_VOLUME_LIST_JSON##*/}"
				doExpand "rFile"
				run_task "${SP_VOLUME_LIST_RUN}" "${SP_FE_JSON_PATH}/${SP_VOLUME_LIST_JSON##*/}" "${SP_VOLUME_LIST_MINUTES}"
			fi
			if [[ -n "${SP_SNAPSHOT_LIST_RUN}" ]]; then
				rFile="${SP_FE_JSON_PATH}/${SP_SNAPSHOT_LIST_JSON##*/}"
				doExpand "rFile"
				run_task "${SP_SNAPSHOT_LIST_RUN}" "${SP_FE_JSON_PATH}/${SP_SNAPSHOT_LIST_JSON##*/}" "${SP_SNAPSHOT_LIST_MINUTES}"
			fi
			if [[ -n "${ONE_VM_POOL_RUN}" ]]; then
				rFile="${SP_FE_JSON_PATH}/${ONE_VM_POOL_XML##*/}"
				doExpand "rFile"
				run_task "${ONE_VM_POOL_RUN}" "${rFile}" "${ONE_VM_POOL_MINUTES}" "" "runonly"
			fi
		fi
	done
#	if boolTrue "DDDEBUG_MOINTOR_HELPER_SYNC"; then
#		splog "[DDD] jFiles:${jFiles[@]}"
#	fi
done
rm -rf "${tmpDir}"
# shellcheck disable=SC2064
trap "rm -f \"${lockFile}\"" TERM INT QUIT HUP EXIT

# hosts processing

tmpXML="$(mktemp --tmpdir onHostList-$$-XXXXXX)"
ret=$?
if [[ ${ret} -ne 0 ]]; then
    splog "(oneHostList) Error: Can't create temp file! (ret:${ret})"
    exit "${ret}"
fi
onehost list -x >"${tmpXML}"
ret=$?
if [[ ${ret} -ne 0 ]]; then
    splog "(oneHostList) Error: Can't get info! $(head -n1 "${tmpXML}" || true) (ret:${ret})"
    exit "${ret}"
fi

_XPATH="${driverPath}/../xpath_multi.py"
_XPATH_A=(
    "${_XPATH}"
    "-s"
)
_XPATH_QUERY=(
    "/HOST_POOL/HOST/ID"
    "/HOST_POOL/HOST/NAME"
    "/HOST_POOL/HOST/STATE"
    "/HOST_POOL/HOST/CLUSTER_ID"
    "/HOST_POOL/HOST/SP_JSON_PATH"
)
unset i XPATH_ELEMENTS
while IFS='' read -r -u "${xpathfd}" element; do
	XPATH_ELEMENTS[i++]="${element}"
done {xpathfd}< <("${_XPATH_A[@]}" <"${tmpXML}" "${_XPATH_QUERY[@]}" || true)
rm -f "${tmpXML}"
unset i
_HOST_ID="${XPATH_ELEMENTS[i++]}"
_HOST_NAME="${XPATH_ELEMENTS[i++]}"
_HOST_STATE="${XPATH_ELEMENTS[i++]}"
_HOST_CLUSTER_ID="${XPATH_ELEMENTS[i++]}"
_HOST_SP_JSON_PATH="${XPATH_ELEMENTS[i++]}"

if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
	splog "[D] ${_HOST_ID}|${_HOST_NAME}|${_HOST_CLUSTER_ID}|${_HOST_STATE}"
fi

IFS=';' read -ra HOST_ID_ARRAY <<<"${_HOST_ID}"
IFS=';' read -ra HOST_NAME_ARRAY <<<"${_HOST_NAME}"
IFS=';' read -ra HOST_STATE_ARRAY <<<"${_HOST_STATE}"
IFS=';' read -ra HOST_CLUSTER_ID_ARRAY <<<"${_HOST_CLUSTER_ID}"
IFS=';' read -ra HOST_SP_JSON_PATH_ARRAY <<<"${_HOST_SP_JSON_PATH}"

_lHost="$(hostname -s || true)"
for i in "${!HOST_ID_ARRAY[@]}"; do
	if [[ "${HOST_ID_ARRAY[i]}" == "" ]]; then
		if boolTrue "DDEBUG_MOINTOR_HELPER_SYNC"; then
			splog "[DD] Skip empty host ID ${i}:${HOST_ID_ARRAY[i]}"
		fi
		continue
	fi
	_rHost="${HOST_NAME_ARRAY[i]}"
	_cluster_id="${HOST_CLUSTER_ID_ARRAY[i]}"
	_destDir="${HOST_SP_JSON_PATH_ARRAY[i]:-${SP_JSON_PATH}}"
	_state="${HOST_STATE_ARRAY[i]}"
	if [[ "${_state}" == "" ]] || [[ ${_state} -ge 4 ]]; then
		if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
			splog "[D] Skip host ${_rHost} state:${_state}"
		fi
		continue
	fi
	SP_MONITOR_CACHE_CLUSTER="${SP_FE_JSON_PATH}/${_cluster_id}"

	if [[ -d "${SP_MONITOR_CACHE_CLUSTER}" ]]; then
		for _jFile in "${jFiles[@]}"; do
			if [[ "${_rHost}" == "${_lHost}" ]]; then
				[[ -d "${_destDir}" ]] || mkdir -p "${_destDir}" && cp -L "${SP_MONITOR_CACHE_CLUSTER}/${_jFile}" "${_destDir}"/
				ret=$?
				if [[ ${ret} -ne 0 ]]; then
					splog "${_rHost} copy ${_jFile} returned ${ret}"
				else
					if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
						splog "[D] ${_rHost} (localhost) ${SP_MONITOR_CACHE_CLUSTER}/${_jFile} copied to ${_destDir} (cluster_id:${_cluster_id})"
					fi
				fi
			elif boolTrue "MONITOR_SYNC_REMOTE" "${MONITOR_SYNC_REMOTE}"; then
                if [[ -f "${SP_MONITOR_CACHE_CLUSTER}/${_jFile}" ]]; then
                    ssh -o ConnectTimeout="${sshConnectTimeout:-3}" \
                        -o ConnectionAttempts="${sshConnectionAttempts:-3}" \
                        "${_rHost}" "[ -d \"${_destDir}\" ] || mkdir -p \"${_destDir}\" && cat >\"${_destDir}/${_jFile}\"" \
							< "${SP_MONITOR_CACHE_CLUSTER}/${_jFile}" \
						2>/dev/null >/dev/null

                    ret=$?
                    if [[ ${ret} -ne 0 ]]; then
                        splog "${_rHost}:${_destDir}/${_jFile} returned ${ret}"
                    else
                        if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
                            splog "[D] ${_rHost} ${SP_MONITOR_CACHE_CLUSTER}/${_jFile} copied to ${_destDir} (cluster_id:${_cluster_id})"
                        fi
                    fi
                else
                    if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
                        splog "[D] File '${SP_MONITOR_CACHE_CLUSTER}/${_jFile}' not found!"
                    fi
                fi
			fi
		done
	else
		if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
			splog "[D] ${_rHost} not on StorPopol cluster? ${SP_MONITOR_CACHE_CLUSTER}"
		fi
	fi
done

rm -f "${lockFile}"

if boolTrue "DEBUG_MOINTOR_HELPER_SYNC"; then
	splog "[D] END"
fi
